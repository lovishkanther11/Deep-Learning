{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_generator4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovishkanther11/Deep-Learning/blob/master/Data_generator4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKHexO4ug2q4",
        "colab_type": "text"
      },
      "source": [
        "#Building powerful image classification models using very little data\n",
        "\n",
        "Aim is to build a powerful image classifier, using only very few training examples\n",
        "\n",
        "Our setup: only 2000 training examples (1000 per class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8jwTf2Pey5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "num_classes = 2\n",
        "#The data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Only look at cats [=3] and dogs [=5]\n",
        "train_picks = np.ravel(np.logical_or(y_train==3,y_train==5))  \n",
        "test_picks = np.ravel(np.logical_or(y_test==3,y_test==5))\n",
        "y_train = np.array(y_train[train_picks]==5,dtype=int)\n",
        "y_test = np.array(y_test[test_picks]==5,dtype=int)\n",
        "x_train = x_train[train_picks]\n",
        "x_test = x_test[test_picks]\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (3, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "    \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#Convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(np.ravel(y_train), num_classes)\n",
        "y_test = keras.utils.to_categorical(np.ravel(y_test), num_classes)\n",
        "\n",
        "#Look at the first 9 images from the dataset\n",
        "images = range(0,9)\n",
        "for i in images:\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
        "    \n",
        "#Show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNSCEsr-k4ec",
        "colab_type": "text"
      },
      "source": [
        "#Create an image generator from ImageDataGenerator()\n",
        "\n",
        "##Randomly Rotate Images\n",
        "\n",
        "1. First we need to create an image generator by calling the ImageDataGenerator() function and pass it a list of parameters describing the alterations that we want it to perform on the images. \n",
        "2. We will then call the fit() function on our image generator which will apply the changes to the images batch by batch.\n",
        "3. You can also use keras.preprocessing to export augmented image files to a folder in order to build up a giant dataset of altered images should you desire to do so.\n",
        "\n",
        "##Randomly Rotate Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvDZpHxJlPbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Rotate images by 90 degrees\n",
        "datagen = ImageDataGenerator(rotation_range=90)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHDHXum3ni5h",
        "colab_type": "text"
      },
      "source": [
        "#Flip Images Vertically\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNAy25PznkCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flip images vertically\n",
        "datagen = ImageDataGenerator(vertical_flip=True)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkcWvUyKnvb6",
        "colab_type": "text"
      },
      "source": [
        "#Shift Images Vertically or Horizontally by 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEfxeTBOnwZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(width_shift_range=.2, \n",
        "                             height_shift_range=.2,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fux9_1OJpXyL",
        "colab_type": "text"
      },
      "source": [
        "#featurewise_center: Boolean. \n",
        "\n",
        "Set input mean to 0 over the dataset, feature-wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlYq1SmxpceO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtcoT8QLpiwq",
        "colab_type": "text"
      },
      "source": [
        "#samplewise_center: Boolean. \n",
        "\n",
        "Set each sample mean to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5Nu_2lopmcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(samplewise_center=True)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C5H_lzTpvFq",
        "colab_type": "text"
      },
      "source": [
        "#featurewise_std_normalization: Boolean. \n",
        "\n",
        "Divide inputs by std of the dataset, feature-wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKS6TOcp0lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(featurewise_std_normalization=True)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PpgLiibp37P",
        "colab_type": "text"
      },
      "source": [
        "#samplewise_std_normalization: Boolean. \n",
        "\n",
        "Divide each input by its std."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx1BqPSep8aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(samplewise_std_normalization=True)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAu-LpWup_RV",
        "colab_type": "text"
      },
      "source": [
        "#zca_epsilon: epsilon for ZCA whitening. \n",
        "\n",
        "Default is 1e-6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oConZJytqDoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(zca_epsilon=1e-05)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouQnxGXlqLmx",
        "colab_type": "text"
      },
      "source": [
        "#zca_whitening: Boolean. \n",
        "\n",
        "Apply ZCA whitening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x3OJsKIqPZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(zca_whitening=True)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNn_9LyUqZW-",
        "colab_type": "text"
      },
      "source": [
        "#rotation_range: Int. \n",
        "\n",
        "Degree range for random rotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vhmHTvVqd14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(rotation_range=30)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7szBRwWqj2Z",
        "colab_type": "text"
      },
      "source": [
        "#width_shift_range: Float, 1-D array-like or int\n",
        "\n",
        "1. float: fraction of total width, if < 1, or pixels if >= 1.\n",
        "2. 1-D array-like: random elements from the array.\n",
        "3. int: integer number of pixels from interval (-width_shift_range, +width_shift_range)\n",
        "\n",
        "With width_shift_range=2 possible values are integers [-1, 0, +1], same as with width_shift_range=[-1, 0, +1], while with width_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0).\n",
        "\n",
        "#height_shift_range: Float, 1-D array-like or int\n",
        "\n",
        "1. float: fraction of total height, if < 1, or pixels if >= 1.\n",
        "2. 1-D array-like: random elements from the array.\n",
        "3. int: integer number of pixels from interval (-height_shift_range, +height_shift_range)\n",
        "\n",
        "With height_shift_range=2 possible values are integers [-1, 0, +1], same as with height_shift_range=[-1, 0, +1], while with height_shift_range=1.0 possible values are floats in the interval [-1.0, +1.0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fbSHseZrdJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL47NejAr0ED",
        "colab_type": "text"
      },
      "source": [
        "#brightness_range: Tuple or list of two floats. \n",
        "\n",
        "Range for picking a brightness shift value from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXh0PRu2r555",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(brightness_range=[0.05,0.06])\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Er6JFosG2h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Other preprocessing\n",
        "\n",
        "1. shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
        "2. zoom_range: Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
        "channel_shift_range: Float. Range for random channel shifts.\n",
        "3. fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default is 'nearest'. Points outside the boundaries of the input are filled according to the given mode:\n",
        "6. horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
        "7. vertical_flip: Boolean. Randomly flip inputs vertically.\n",
        "8. rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (after applying all other transformations)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_wrczR-sn0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shift images vertically or horizontally \n",
        "# Fill missing pixels with the color of the nearest pixel\n",
        "datagen = ImageDataGenerator(shear_range=0.1,zoom_range=0.1,fill_mode=\"nearest\",horizontal_flip=True,vertical_flip=True,rescale=0)\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].reshape(img_rows, img_cols, 3))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6TfKKBQw0oC",
        "colab_type": "text"
      },
      "source": [
        "#Saving Augmented Images to File\n",
        "\n",
        "The data preparation and augmentation is performed just in time by Keras.\n",
        "\n",
        "This is efficient in terms of memory, but you may require the exact images used during training. For example, perhaps you would like to use them with a different software package later or only generate them once and use them on multiple different deep learning models or configurations.\n",
        "\n",
        "Keras allows you to save the images generated during training. The directory, filename prefix and image file type can be specified to the flow() function before training. Then, during training, the generated images will be written to file.\n",
        "\n",
        "The example below demonstrates this and writes 9 images to a “images” subdirectory with the prefix “aug” and the file type of PNG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l_fOnXrw5-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save augmented images to file\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "import os\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator()\n",
        "# fit parameters from data\n",
        "datagen.fit(X_train)\n",
        "# configure batch size and retrieve one batch of images\n",
        "os.makedirs('images')\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, save_to_dir='images', save_prefix='aug', save_format='png'):\n",
        "\t# create a grid of 3x3 images\n",
        "\tfor i in range(0, 9):\n",
        "\t\tpyplot.subplot(330 + 1 + i)\n",
        "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
        "\t# show the plot\n",
        "\tpyplot.show()\n",
        "\tbreak"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e9b0PrxgF1",
        "colab_type": "text"
      },
      "source": [
        "#Examples\n",
        "\n",
        "Training models on augmented data on CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-z_MXkFtiyr",
        "colab_type": "code",
        "outputId": "d2785bf0-5694-46b1-b0ec-d8741c3d4a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import cifar100\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Conv2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "epochs=10\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#We need to use a Conv2D layer at start of the neural network \n",
        "#the syntax is Conv2D(1, (image_width,image_height), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:])\n",
        "#the we add a flatten layer\n",
        "model.add(Conv2D(1024, (32, 32), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "#then we continue with the neural network.\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(X_train, Y_train),epochs=epochs,verbose=1, validation_data=datagen.flow(X_test, Y_test))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 1.9451 - acc: 0.2982 - val_loss: 1.8165 - val_acc: 0.3522\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.8046 - acc: 0.3523 - val_loss: 1.7668 - val_acc: 0.3692\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7478 - acc: 0.3740 - val_loss: 1.6977 - val_acc: 0.3841\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7095 - acc: 0.3876 - val_loss: 1.7087 - val_acc: 0.3980\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.6787 - acc: 0.3988 - val_loss: 1.6565 - val_acc: 0.4065\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6564 - acc: 0.4079 - val_loss: 1.6424 - val_acc: 0.4150\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6317 - acc: 0.4150 - val_loss: 1.6090 - val_acc: 0.4295\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6175 - acc: 0.4198 - val_loss: 1.6335 - val_acc: 0.4129\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6028 - acc: 0.4257 - val_loss: 1.6219 - val_acc: 0.4203\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.5909 - acc: 0.4302 - val_loss: 1.5637 - val_acc: 0.4445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65fa158f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h_HxWQsVwQr",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 10**\n",
        "\n",
        "acc: 0.4302\n",
        "\n",
        "val_acc: 0.4445"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axFE1hGEyadT",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-CVLajWpoYu",
        "colab_type": "code",
        "outputId": "960a62dd-6bff-49b2-e39f-ada0c9eeb23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import cifar100\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Conv2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "epochs=10\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 28,28,1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28,28,1))\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#We need to use a Conv2D layer at start of the neural network \n",
        "#the syntax is Conv2D(1, (image_width,image_height), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:])\n",
        "#the we add a flatten layer\n",
        "model.add(Conv2D(1024, (28, 28), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "#then we continue with the neural network.\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(X_train, Y_train),epochs=epochs,verbose=1, validation_data=datagen.flow(X_test, Y_test))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.8528 - acc: 0.7069 - val_loss: 0.5607 - val_acc: 0.8154\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.5080 - acc: 0.8337 - val_loss: 0.4636 - val_acc: 0.8451\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.4282 - acc: 0.8614 - val_loss: 0.4207 - val_acc: 0.8656\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.3977 - acc: 0.8736 - val_loss: 0.3647 - val_acc: 0.8821\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.3596 - acc: 0.8844 - val_loss: 0.3338 - val_acc: 0.8959\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.3445 - acc: 0.8908 - val_loss: 0.3438 - val_acc: 0.8887\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.3245 - acc: 0.8968 - val_loss: 0.3059 - val_acc: 0.9048\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.3095 - acc: 0.9013 - val_loss: 0.2929 - val_acc: 0.9095\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.3001 - acc: 0.9060 - val_loss: 0.3067 - val_acc: 0.9036\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2874 - acc: 0.9108 - val_loss: 0.2785 - val_acc: 0.9112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65f9f753c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCcYXfFsUx2o",
        "colab_type": "text"
      },
      "source": [
        "**MNIST**\n",
        "\n",
        "acc: 0.9108\n",
        "\n",
        "val_acc: 0.9112"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJu9FyRsqaro",
        "colab_type": "code",
        "outputId": "aa236e29-9f44-41ef-b9a2-7740b2b8d3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import cifar100\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Conv2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "epochs=10\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 28,28,1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28,28,1))\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#We need to use a Conv2D layer at start of the neural network \n",
        "#the syntax is Conv2D(1, (image_width,image_height), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:])\n",
        "#the we add a flatten layer\n",
        "model.add(Conv2D(1024, (28, 28), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "#then we continue with the neural network.\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(X_train, Y_train),epochs=epochs,verbose=1, validation_data=datagen.flow(X_test, Y_test))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.9633 - acc: 0.6323 - val_loss: 0.8674 - val_acc: 0.6670\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.7901 - acc: 0.6979 - val_loss: 0.7659 - val_acc: 0.7121\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.7351 - acc: 0.7195 - val_loss: 0.7101 - val_acc: 0.7276\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.7001 - acc: 0.7325 - val_loss: 0.6975 - val_acc: 0.7403\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.6772 - acc: 0.7412 - val_loss: 0.6757 - val_acc: 0.7486\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.6526 - acc: 0.7507 - val_loss: 0.6522 - val_acc: 0.7567\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.6408 - acc: 0.7559 - val_loss: 0.6440 - val_acc: 0.7567\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.6371 - acc: 0.7566 - val_loss: 0.6348 - val_acc: 0.7564\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.6211 - acc: 0.7651 - val_loss: 0.6270 - val_acc: 0.7678\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.6188 - acc: 0.7658 - val_loss: 0.6331 - val_acc: 0.7616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65f95c3160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcGwegQ-Vo7z",
        "colab_type": "text"
      },
      "source": [
        "**FASHION MNIST**\n",
        "\n",
        "acc: 0.7658 \n",
        "\n",
        " val_acc: 0.7616"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzlkMxB5t0et",
        "colab_type": "code",
        "outputId": "811171f3-eb94-4d93-8fe4-e3b324589b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import cifar100\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Conv2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "epochs=10\n",
        "\n",
        "#import dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(y_train, 100)\n",
        "Y_test =  to_categorical(y_test, 100)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#We need to use a Conv2D layer at start of the neural network \n",
        "#the syntax is Conv2D(1, (image_width,image_height), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:])\n",
        "#the we add a flatten layer\n",
        "model.add(Conv2D(1024, (32, 32), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "#then we continue with the neural network.\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(X_train, Y_train),epochs=epochs,verbose=1, validation_data=datagen.flow(X_test, Y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 4.1172 - acc: 0.0697 - val_loss: 3.9964 - val_acc: 0.0895\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 3.8837 - acc: 0.1010 - val_loss: 3.8503 - val_acc: 0.1095\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 3.7921 - acc: 0.1154 - val_loss: 3.7949 - val_acc: 0.1176\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 3.7381 - acc: 0.1225 - val_loss: 3.7695 - val_acc: 0.1278\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 3.6941 - acc: 0.1301 - val_loss: 3.7557 - val_acc: 0.1283\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 3.6668 - acc: 0.1348 - val_loss: 3.7335 - val_acc: 0.1320\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 3.6437 - acc: 0.1379 - val_loss: 3.7041 - val_acc: 0.1343\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 3.6273 - acc: 0.1429 - val_loss: 3.6633 - val_acc: 0.1403\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 3.6063 - acc: 0.1453 - val_loss: 3.6503 - val_acc: 0.1398\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 3.5941 - acc: 0.1485 - val_loss: 3.6485 - val_acc: 0.1397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65f943cd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}