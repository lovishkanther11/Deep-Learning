{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovishkanther11/Deep-Learning/blob/master/Keras_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJdKMnxbQ35X",
        "colab_type": "text"
      },
      "source": [
        "#Usage of metrics\n",
        "\n",
        "A metric is a function that is used to judge the performance of your model. Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=['mae', 'acc'])\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=[metrics.mae, metrics.categorical_accuracy])\n",
        "```\n",
        "\n",
        "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function.\n",
        "\n",
        "You can either pass the name of an existing metric, or pass a Theano/TensorFlow symbolic function (see Custom metrics).\n",
        "\n",
        "##Arguments\n",
        "1. y_true: True labels. Theano/TensorFlow tensor.\n",
        "2. y_pred: Predictions. Theano/TensorFlow tensor of the same shape as y_true.\n",
        "\n",
        "##Returns\n",
        "\n",
        "1. Single tensor value representing the mean of the output array across all datapoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_roXIFgkRIRf",
        "colab_type": "text"
      },
      "source": [
        "#Accuracy\n",
        "keras.metrics.accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXkjmUIiROMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a148b38c-f5ea-4437-80f6-afa3f914ca6e"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.2901 - acc: 0.9114 - val_loss: 0.1740 - val_acc: 0.9436\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1222 - acc: 0.9626 - val_loss: 0.1131 - val_acc: 0.9649\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0836 - acc: 0.9739 - val_loss: 0.0945 - val_acc: 0.9718\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0634 - acc: 0.9800 - val_loss: 0.0888 - val_acc: 0.9723\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0510 - acc: 0.9837 - val_loss: 0.0810 - val_acc: 0.9750\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0414 - acc: 0.9868 - val_loss: 0.0843 - val_acc: 0.9753\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0340 - acc: 0.9886 - val_loss: 0.0761 - val_acc: 0.9797\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0278 - acc: 0.9910 - val_loss: 0.0901 - val_acc: 0.9755\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.1046 - val_acc: 0.9752\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0214 - acc: 0.9929 - val_loss: 0.0875 - val_acc: 0.9794\n",
            "Test loss: 0.08748246689389834\n",
            "Test accuracy: 0.9794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTHlkI9CRX4M",
        "colab_type": "text"
      },
      "source": [
        "#binary_accuracy\n",
        "\n",
        "keras.metrics.binary_accuracy(y_true, y_pred, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yJ88okURbcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "593b296c-7eb3-443d-a5fc-dd8d4d9ec7fa"
      },
      "source": [
        "# Compile model using binary_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0188 - binary_accuracy: 0.9988 - val_loss: 0.0881 - val_binary_accuracy: 0.9961\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0163 - binary_accuracy: 0.9990 - val_loss: 0.1066 - val_binary_accuracy: 0.9959\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0140 - binary_accuracy: 0.9991 - val_loss: 0.1055 - val_binary_accuracy: 0.9961\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0118 - binary_accuracy: 0.9992 - val_loss: 0.1032 - val_binary_accuracy: 0.9962\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0111 - binary_accuracy: 0.9993 - val_loss: 0.1100 - val_binary_accuracy: 0.9961\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0110 - binary_accuracy: 0.9993 - val_loss: 0.1122 - val_binary_accuracy: 0.9960\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0100 - binary_accuracy: 0.9994 - val_loss: 0.1211 - val_binary_accuracy: 0.9957\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0097 - binary_accuracy: 0.9995 - val_loss: 0.1041 - val_binary_accuracy: 0.9962\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0082 - binary_accuracy: 0.9994 - val_loss: 0.1179 - val_binary_accuracy: 0.9961\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0076 - binary_accuracy: 0.9996 - val_loss: 0.1110 - val_binary_accuracy: 0.9963\n",
            "Test loss: 0.1110117813333877\n",
            "Test accuracy: 0.9962999961853027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i34lhk62Rr00",
        "colab_type": "text"
      },
      "source": [
        "#categorical_accuracy\n",
        "\n",
        "keras.metrics.categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yiFITLRut3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "72cfbaa8-2c47-4e80-ada6-02a79c6766bf"
      },
      "source": [
        "# Compile model using categorical_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0079 - categorical_accuracy: 0.9977 - val_loss: 0.1220 - val_categorical_accuracy: 0.9811\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0066 - categorical_accuracy: 0.9981 - val_loss: 0.1182 - val_categorical_accuracy: 0.9813\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0059 - categorical_accuracy: 0.9983 - val_loss: 0.1320 - val_categorical_accuracy: 0.9806\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0056 - categorical_accuracy: 0.9984 - val_loss: 0.1303 - val_categorical_accuracy: 0.9817\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0062 - categorical_accuracy: 0.9984 - val_loss: 0.1326 - val_categorical_accuracy: 0.9806\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0062 - categorical_accuracy: 0.9985 - val_loss: 0.1435 - val_categorical_accuracy: 0.9808\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0049 - categorical_accuracy: 0.9987 - val_loss: 0.1426 - val_categorical_accuracy: 0.9811\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0057 - categorical_accuracy: 0.9982 - val_loss: 0.1451 - val_categorical_accuracy: 0.9803\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0046 - categorical_accuracy: 0.9987 - val_loss: 0.1420 - val_categorical_accuracy: 0.9812\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0039 - categorical_accuracy: 0.9990 - val_loss: 0.1550 - val_categorical_accuracy: 0.9807\n",
            "Test loss: 0.15496718782309557\n",
            "Test accuracy: 0.9807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2C271EXSqnV",
        "colab_type": "text"
      },
      "source": [
        "#top_k_categorical_accuracy\n",
        "\n",
        "keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hdQEGZSsKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "2ad44afe-251f-4130-891e-3abf41da0536"
      },
      "source": [
        "# Compile model using categorical_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0059 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1421 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0054 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1343 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0046 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1569 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0048 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1506 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0031 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1663 - val_top_k_categorical_accuracy: 0.9997\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0039 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1489 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0039 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1542 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0031 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1404 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0035 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1501 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0036 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1504 - val_top_k_categorical_accuracy: 0.9999\n",
            "Test loss: 0.15037242276851046\n",
            "Test accuracy: 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WTKc7LCR22d",
        "colab_type": "text"
      },
      "source": [
        "#sparse_categorical_accuracy\n",
        "\n",
        "keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpEKVQaQR-iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6eb624c-3980-438c-affe-65d456be8d29"
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.7395 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.7392 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.7389 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.7385 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.7381 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.7377 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.7374 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.7370 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.7366 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.7362 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.7358 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.7355 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.7351 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.7347 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.7344 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.7340 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.7336 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.7333 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.7329 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.7326 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.7322 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.7319 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.7315 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7312 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7308 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7305 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7302 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7298 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7295 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7292 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7288 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7285 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7282 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7279 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.7276 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.7273 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.7270 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.7267 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.7264 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.7261 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.7258 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.7255 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.7252 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.7249 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.7246 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.7244 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.7241 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.7238 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.7235 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.7233 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.7230 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.7227 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.7225 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.7222 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.7220 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.7217 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.7214 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.7212 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.7209 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.7207 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.7204 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.7202 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.7200 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.7197 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.7195 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.7192 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.7190 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.7188 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.7185 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.7183 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.7181 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.7178 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.7176 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.7174 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.7172 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.7169 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7167 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7165 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7163 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.7161 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.7159 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.7156 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.7154 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.7152 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.7150 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.7148 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.7146 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.7144 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.7142 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.7140 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.7138 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.7135 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.7133 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.7131 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.7129 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.7127 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.7125 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.7123 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.7121 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.7119 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.7118 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.7116 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.7114 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.7112 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.7110 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.7108 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.7106 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.7104 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.7102 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.7100 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.7098 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.7096 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.7094 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.7093 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.7091 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.7089 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.7087 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.7085 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.7083 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.7081 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.7080 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.7078 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.7076 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.7074 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.7072 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.7071 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.7069 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.7067 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.7065 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.7063 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.7062 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.7060 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.7058 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.7056 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.7054 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.7053 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.7051 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.7049 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.7047 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.7046 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.7044 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.7042 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.7040 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.7039 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.7037 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.7035 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.7033 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.7032 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.7030 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.7028 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.7027 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.7025 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.7023 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.7021 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.7020 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.7018 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.7016 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.7015 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.7013 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.7011 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.7010 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.7008 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.7006 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.7004 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.7003 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.7001 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.6999 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.6998 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.6996 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.6994 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.6993 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.6991 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.6989 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.6988 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.6986 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.6985 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.6983 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.6981 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.6980 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.6978 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.6976 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.6975 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.6973 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.6971 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.6970 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.6968 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.6966 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.6965 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.6963 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.6962 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.6960 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.6958 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.6957 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.6955 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.6953 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.6952 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.6950 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.6949 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.6947 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.6945 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.6944 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.6942 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.6941 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.6939 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.6937 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.6936 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.6934 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.6932 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.6931 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.6929 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.6928 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.6926 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.6924 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.6923 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.6921 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.6920 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.6918 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.6916 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.6915 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.6913 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.6912 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.6910 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.6908 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.6907 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.6905 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.6904 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.6902 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.6900 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.6899 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.6897 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.6896 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.6894 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.6892 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.6891 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.6889 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.6888 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.6886 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.6884 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.6883 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.6881 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.6880 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.6878 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.6876 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.6875 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.6873 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.6871 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.6870 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.6868 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.6867 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.6865 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.6863 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.6862 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.6860 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.6859 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.6857 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.6855 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.6854 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.6852 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.6850 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.6849 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.6847 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.6845 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.6844 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.6842 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.6841 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.6839 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.6837 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.6836 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.6834 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.6832 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.6831 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.6829 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.6827 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.6826 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.6824 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.6822 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.6821 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.6819 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.6817 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.6816 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.6814 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.6812 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.6811 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.6809 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.6807 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.6806 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.6804 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.6802 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.6800 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.6799 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.6797 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.6795 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.6794 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.6792 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.6790 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.6788 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.6787 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.6785 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.6783 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.6781 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6780 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6778 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6776 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6774 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6773 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6771 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6769 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6767 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6766 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6764 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6762 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6760 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6758 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6757 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6755 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6753 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6751 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6749 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6748 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6746 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6744 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6742 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6740 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6738 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6737 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6735 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6733 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6731 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6729 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6727 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6725 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.6724 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.6722 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.6720 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.6718 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.6716 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.6714 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.6712 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.6710 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.6708 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.6707 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.6705 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.6703 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.6701 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.6699 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.6697 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.6695 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.6693 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.6691 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.6689 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.6687 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.6685 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.6683 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.6681 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.6679 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.6677 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.6675 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.6673 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.6671 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.6669 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.6667 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.6665 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.6663 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.6661 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.6659 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.6657 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.6655 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.6653 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.6651 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.6649 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.6647 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.6645 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.6642 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.6640 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.6638 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.6636 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.6634 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.6632 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.6630 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.6628 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.6626 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.6623 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.6621 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.6619 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.6617 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.6615 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.6613 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.6610 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.6608 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.6606 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.6604 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.6602 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.6600 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.6597 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.6595 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.6593 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.6591 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.6588 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.6586 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.6584 - sparse_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHCFoRZKUdki",
        "colab_type": "text"
      },
      "source": [
        "#sparse_top_k_categorical_accuracy\n",
        "\n",
        "keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FWdLp_UfPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58b27ff6-c852-460e-cd18-cbff8ed32260"
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['sparse_top_k_categorical_accuracy'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.7828 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.7821 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.7814 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.7808 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.7801 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.7794 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.7788 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.7781 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.7775 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.7768 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.7762 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.7756 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.7749 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.7743 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.7737 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.7730 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.7724 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.7718 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.7712 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.7706 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.7700 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.7694 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.7688 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7682 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7676 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7670 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7664 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7658 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7653 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7647 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7641 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7636 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7630 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7624 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.7619 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.7613 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.7608 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.7603 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.7597 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.7592 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.7587 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.7581 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.7576 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.7571 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.7566 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.7561 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.7556 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.7550 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.7545 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.7540 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.7535 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.7531 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.7526 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.7521 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.7516 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.7511 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.7507 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.7502 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.7497 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.7492 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.7488 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.7483 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.7479 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.7474 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.7470 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.7465 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.7461 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.7456 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.7452 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.7448 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.7443 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.7439 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.7435 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.7430 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.7426 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.7422 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7418 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7414 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7410 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.7406 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.7401 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.7397 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.7393 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.7389 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.7385 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.7381 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.7378 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.7374 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.7370 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.7366 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.7362 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.7358 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.7354 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.7351 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.7347 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.7343 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.7339 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.7336 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.7332 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.7328 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.7325 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.7321 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.7317 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.7314 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.7310 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.7307 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.7303 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.7300 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.7296 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.7292 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.7289 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.7286 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.7282 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.7279 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.7275 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.7272 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.7268 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.7265 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.7261 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.7258 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.7255 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.7251 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.7248 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.7245 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.7241 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.7238 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.7235 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.7231 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.7228 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.7225 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.7221 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.7218 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.7215 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.7211 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.7208 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.7205 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.7202 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.7198 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.7195 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.7192 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.7189 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.7185 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.7182 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.7179 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.7176 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.7173 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.7169 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.7166 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.7163 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.7160 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.7157 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.7153 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.7150 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.7147 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.7144 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.7141 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.7137 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.7134 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.7131 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.7128 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.7125 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.7121 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.7118 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.7115 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.7112 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.7109 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.7106 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.7102 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.7099 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.7096 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.7093 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.7090 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.7087 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.7083 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.7080 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.7077 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.7074 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.7071 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.7068 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.7064 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.7061 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.7058 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.7055 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.7052 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.7049 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.7045 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.7042 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.7039 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.7036 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.7033 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.7029 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.7026 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.7023 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.7020 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.7017 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.7014 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.7010 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.7007 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.7004 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.7001 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.6998 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.6994 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.6991 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.6988 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.6985 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.6982 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.6978 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.6975 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.6972 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.6969 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.6965 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.6962 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.6959 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.6956 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.6953 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.6949 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.6946 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.6943 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.6940 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.6936 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.6933 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.6930 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.6927 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.6924 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.6920 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.6917 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.6914 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.6911 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.6907 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.6904 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.6901 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.6898 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.6894 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.6891 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.6888 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.6885 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.6881 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.6878 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.6875 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.6871 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.6868 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.6865 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.6862 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.6858 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.6855 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.6852 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.6849 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.6845 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.6842 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.6839 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.6835 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.6832 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.6829 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.6826 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.6822 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.6819 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.6816 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.6812 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.6809 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.6806 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.6802 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.6799 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.6796 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.6792 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.6789 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.6786 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.6783 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.6779 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.6776 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.6773 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.6769 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.6766 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.6763 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.6759 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.6756 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.6753 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.6749 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.6746 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.6743 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.6739 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.6736 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.6733 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.6729 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.6726 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.6723 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.6719 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.6716 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.6713 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.6709 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.6706 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.6702 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.6699 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.6696 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.6692 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.6689 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.6686 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.6682 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.6679 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.6676 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.6672 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6669 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6665 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6662 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6659 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6655 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6652 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6649 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6645 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6642 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6638 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6635 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6632 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6628 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6625 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6622 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6618 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6615 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6611 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6608 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6605 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6601 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6598 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6594 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6591 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6588 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6584 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6581 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6577 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6574 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6571 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6567 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.6564 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.6560 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.6557 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.6553 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.6550 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.6547 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.6543 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.6540 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.6536 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.6533 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.6530 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.6526 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.6523 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.6519 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.6516 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.6512 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.6509 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.6506 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.6502 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.6499 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.6495 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.6492 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.6488 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.6485 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.6482 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.6478 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.6475 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.6471 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.6468 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.6464 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.6461 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.6457 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.6454 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.6451 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.6447 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.6444 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.6440 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.6437 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.6433 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.6430 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.6426 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.6423 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.6419 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.6416 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.6413 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.6409 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.6406 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.6402 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.6399 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.6395 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.6392 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.6388 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.6385 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.6381 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.6378 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.6374 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.6371 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.6368 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.6364 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.6361 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.6357 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.6354 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.6350 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.6347 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.6343 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.6340 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.6336 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.6333 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.6329 - sparse_top_k_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MljdGHXMUwYr",
        "colab_type": "text"
      },
      "source": [
        "#cosine_proximity\n",
        "\n",
        "keras.metrics.cosine_proximity(y_true, y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfLN9tE6UyQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a4d1dbd-2e97-4bf3-ce9a-54b328df5eed"
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['cosine_proximity'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.6855 - cosine_proximity: -5.0000e-01\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.6854 - cosine_proximity: -5.0000e-01\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.6852 - cosine_proximity: -5.0000e-01\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.6851 - cosine_proximity: -5.0000e-01\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.6850 - cosine_proximity: -5.0000e-01\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.6849 - cosine_proximity: -5.0000e-01\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.6847 - cosine_proximity: -5.0000e-01\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.6846 - cosine_proximity: -5.0000e-01\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.6845 - cosine_proximity: -5.0000e-01\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.6843 - cosine_proximity: -5.0000e-01\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.6842 - cosine_proximity: -5.0000e-01\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.6841 - cosine_proximity: -5.0000e-01\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.6840 - cosine_proximity: -5.0000e-01\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.6838 - cosine_proximity: -5.0000e-01\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.6837 - cosine_proximity: -5.0000e-01\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.6836 - cosine_proximity: -5.0000e-01\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.6834 - cosine_proximity: -5.0000e-01\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.6833 - cosine_proximity: -5.0000e-01\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.6832 - cosine_proximity: -5.0000e-01\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.6830 - cosine_proximity: -5.0000e-01\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.6829 - cosine_proximity: -5.0000e-01\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.6828 - cosine_proximity: -5.0000e-01\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.6827 - cosine_proximity: -5.0000e-01\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.6825 - cosine_proximity: -5.0000e-01\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.6824 - cosine_proximity: -5.0000e-01\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.6823 - cosine_proximity: -5.0000e-01\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.6821 - cosine_proximity: -5.0000e-01\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.6820 - cosine_proximity: -5.0000e-01\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.6819 - cosine_proximity: -5.0000e-01\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.6818 - cosine_proximity: -5.0000e-01\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.6816 - cosine_proximity: -5.0000e-01\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.6815 - cosine_proximity: -5.0000e-01\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.6814 - cosine_proximity: -5.0000e-01\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.6812 - cosine_proximity: -5.0000e-01\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.6811 - cosine_proximity: -5.0000e-01\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.6810 - cosine_proximity: -5.0000e-01\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.6809 - cosine_proximity: -5.0000e-01\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.6807 - cosine_proximity: -5.0000e-01\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.6806 - cosine_proximity: -5.0000e-01\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.6805 - cosine_proximity: -5.0000e-01\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.6803 - cosine_proximity: -5.0000e-01\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.6802 - cosine_proximity: -5.0000e-01\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.6801 - cosine_proximity: -5.0000e-01\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.6799 - cosine_proximity: -5.0000e-01\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.6798 - cosine_proximity: -5.0000e-01\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.6796 - cosine_proximity: -5.0000e-01\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.6795 - cosine_proximity: -5.0000e-01\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.6794 - cosine_proximity: -5.0000e-01\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.6792 - cosine_proximity: -5.0000e-01\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.6791 - cosine_proximity: -5.0000e-01\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.6790 - cosine_proximity: -5.0000e-01\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.6788 - cosine_proximity: -5.0000e-01\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.6787 - cosine_proximity: -5.0000e-01\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.6785 - cosine_proximity: -5.0000e-01\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.6784 - cosine_proximity: -5.0000e-01\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.6782 - cosine_proximity: -5.0000e-01\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.6781 - cosine_proximity: -5.0000e-01\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.6779 - cosine_proximity: -5.0000e-01\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.6778 - cosine_proximity: -5.0000e-01\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.6776 - cosine_proximity: -5.0000e-01\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.6775 - cosine_proximity: -5.0000e-01\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.6773 - cosine_proximity: -5.0000e-01\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.6772 - cosine_proximity: -5.0000e-01\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.6770 - cosine_proximity: -5.0000e-01\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.6769 - cosine_proximity: -5.0000e-01\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.6767 - cosine_proximity: -5.0000e-01\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.6766 - cosine_proximity: -5.0000e-01\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.6764 - cosine_proximity: -5.0000e-01\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.6763 - cosine_proximity: -5.0000e-01\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.6761 - cosine_proximity: -5.0000e-01\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.6759 - cosine_proximity: -5.0000e-01\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.6758 - cosine_proximity: -5.0000e-01\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.6756 - cosine_proximity: -5.0000e-01\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.6755 - cosine_proximity: -5.0000e-01\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.6753 - cosine_proximity: -5.0000e-01\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.6751 - cosine_proximity: -5.0000e-01\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.6750 - cosine_proximity: -5.0000e-01\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.6748 - cosine_proximity: -5.0000e-01\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.6746 - cosine_proximity: -5.0000e-01\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.6745 - cosine_proximity: -5.0000e-01\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.6743 - cosine_proximity: -5.0000e-01\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.6741 - cosine_proximity: -5.0000e-01\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.6740 - cosine_proximity: -5.0000e-01\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.6738 - cosine_proximity: -5.0000e-01\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.6736 - cosine_proximity: -5.0000e-01\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.6734 - cosine_proximity: -5.0000e-01\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.6733 - cosine_proximity: -5.0000e-01\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.6731 - cosine_proximity: -5.0000e-01\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.6729 - cosine_proximity: -5.0000e-01\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.6727 - cosine_proximity: -5.0000e-01\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.6726 - cosine_proximity: -5.0000e-01\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.6724 - cosine_proximity: -5.0000e-01\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.6722 - cosine_proximity: -5.0000e-01\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.6720 - cosine_proximity: -5.0000e-01\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.6718 - cosine_proximity: -5.0000e-01\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.6716 - cosine_proximity: -5.0000e-01\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.6715 - cosine_proximity: -5.0000e-01\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.6713 - cosine_proximity: -5.0000e-01\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.6711 - cosine_proximity: -5.0000e-01\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.6709 - cosine_proximity: -5.0000e-01\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.6707 - cosine_proximity: -5.0000e-01\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.6705 - cosine_proximity: -5.0000e-01\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.6703 - cosine_proximity: -5.0000e-01\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.6701 - cosine_proximity: -5.0000e-01\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.6699 - cosine_proximity: -5.0000e-01\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.6698 - cosine_proximity: -5.0000e-01\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.6696 - cosine_proximity: -5.0000e-01\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.6694 - cosine_proximity: -5.0000e-01\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.6692 - cosine_proximity: -5.0000e-01\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.6690 - cosine_proximity: -5.0000e-01\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.6688 - cosine_proximity: -5.0000e-01\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.6686 - cosine_proximity: -5.0000e-01\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.6684 - cosine_proximity: -5.0000e-01\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.6682 - cosine_proximity: -5.0000e-01\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.6680 - cosine_proximity: -5.0000e-01\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.6678 - cosine_proximity: -5.0000e-01\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.6676 - cosine_proximity: -5.0000e-01\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.6674 - cosine_proximity: -5.0000e-01\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.6671 - cosine_proximity: -5.0000e-01\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.6669 - cosine_proximity: -5.0000e-01\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.6667 - cosine_proximity: -5.0000e-01\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.6665 - cosine_proximity: -5.0000e-01\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.6663 - cosine_proximity: -5.0000e-01\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.6661 - cosine_proximity: -5.0000e-01\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.6659 - cosine_proximity: -5.0000e-01\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.6657 - cosine_proximity: -5.0000e-01\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.6655 - cosine_proximity: -5.0000e-01\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.6652 - cosine_proximity: -5.0000e-01\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.6650 - cosine_proximity: -5.0000e-01\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.6648 - cosine_proximity: -5.0000e-01\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.6646 - cosine_proximity: -5.0000e-01\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.6644 - cosine_proximity: -5.0000e-01\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.6641 - cosine_proximity: -5.0000e-01\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.6639 - cosine_proximity: -5.0000e-01\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.6637 - cosine_proximity: -5.0000e-01\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.6635 - cosine_proximity: -5.0000e-01\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.6632 - cosine_proximity: -5.0000e-01\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.6630 - cosine_proximity: -5.0000e-01\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.6628 - cosine_proximity: -5.0000e-01\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.6626 - cosine_proximity: -5.0000e-01\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.6623 - cosine_proximity: -5.0000e-01\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.6621 - cosine_proximity: -5.0000e-01\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.6619 - cosine_proximity: -5.0000e-01\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.6616 - cosine_proximity: -5.0000e-01\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.6614 - cosine_proximity: -5.0000e-01\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.6612 - cosine_proximity: -5.0000e-01\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.6609 - cosine_proximity: -5.0000e-01\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.6607 - cosine_proximity: -5.0000e-01\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.6605 - cosine_proximity: -5.0000e-01\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.6602 - cosine_proximity: -5.0000e-01\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.6600 - cosine_proximity: -5.0000e-01\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.6597 - cosine_proximity: -5.0000e-01\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.6595 - cosine_proximity: -5.0000e-01\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.6593 - cosine_proximity: -5.0000e-01\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.6590 - cosine_proximity: -5.0000e-01\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.6588 - cosine_proximity: -5.0000e-01\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.6585 - cosine_proximity: -5.0000e-01\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.6583 - cosine_proximity: -5.0000e-01\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.6580 - cosine_proximity: -5.0000e-01\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.6578 - cosine_proximity: -5.0000e-01\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.6575 - cosine_proximity: -5.0000e-01\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.6573 - cosine_proximity: -5.0000e-01\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.6570 - cosine_proximity: -5.0000e-01\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.6568 - cosine_proximity: -5.0000e-01\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.6565 - cosine_proximity: -5.0000e-01\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.6563 - cosine_proximity: -5.0000e-01\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.6560 - cosine_proximity: -5.0000e-01\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.6558 - cosine_proximity: -5.0000e-01\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.6555 - cosine_proximity: -5.0000e-01\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.6553 - cosine_proximity: -5.0000e-01\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.6550 - cosine_proximity: -5.0000e-01\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.6547 - cosine_proximity: -5.0000e-01\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.6545 - cosine_proximity: -5.0000e-01\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.6542 - cosine_proximity: -5.0000e-01\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.6540 - cosine_proximity: -5.0000e-01\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.6537 - cosine_proximity: -5.0000e-01\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.6534 - cosine_proximity: -5.0000e-01\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.6532 - cosine_proximity: -5.0000e-01\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.6529 - cosine_proximity: -5.0000e-01\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.6526 - cosine_proximity: -5.0000e-01\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.6524 - cosine_proximity: -5.0000e-01\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.6521 - cosine_proximity: -5.0000e-01\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.6518 - cosine_proximity: -5.0000e-01\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.6515 - cosine_proximity: -5.0000e-01\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.6513 - cosine_proximity: -5.0000e-01\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.6510 - cosine_proximity: -5.0000e-01\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.6507 - cosine_proximity: -5.0000e-01\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.6505 - cosine_proximity: -5.0000e-01\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.6502 - cosine_proximity: -5.0000e-01\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.6499 - cosine_proximity: -5.0000e-01\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.6496 - cosine_proximity: -5.0000e-01\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.6493 - cosine_proximity: -5.0000e-01\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.6491 - cosine_proximity: -5.0000e-01\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.6488 - cosine_proximity: -5.0000e-01\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.6485 - cosine_proximity: -5.0000e-01\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.6482 - cosine_proximity: -5.0000e-01\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.6479 - cosine_proximity: -5.0000e-01\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.6476 - cosine_proximity: -5.0000e-01\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.6474 - cosine_proximity: -5.0000e-01\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.6471 - cosine_proximity: -5.0000e-01\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.6468 - cosine_proximity: -5.0000e-01\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.6465 - cosine_proximity: -5.0000e-01\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.6462 - cosine_proximity: -5.0000e-01\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.6459 - cosine_proximity: -5.0000e-01\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.6456 - cosine_proximity: -5.0000e-01\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.6453 - cosine_proximity: -5.0000e-01\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.6450 - cosine_proximity: -5.0000e-01\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.6448 - cosine_proximity: -5.0000e-01\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.6445 - cosine_proximity: -5.0000e-01\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.6442 - cosine_proximity: -5.0000e-01\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.6439 - cosine_proximity: -5.0000e-01\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.6436 - cosine_proximity: -5.0000e-01\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.6433 - cosine_proximity: -5.0000e-01\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.6430 - cosine_proximity: -5.0000e-01\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.6427 - cosine_proximity: -5.0000e-01\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.6424 - cosine_proximity: -5.0000e-01\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.6421 - cosine_proximity: -5.0000e-01\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.6418 - cosine_proximity: -5.0000e-01\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.6415 - cosine_proximity: -5.0000e-01\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.6412 - cosine_proximity: -5.0000e-01\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.6409 - cosine_proximity: -5.0000e-01\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.6406 - cosine_proximity: -5.0000e-01\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.6402 - cosine_proximity: -5.0000e-01\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.6399 - cosine_proximity: -5.0000e-01\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.6396 - cosine_proximity: -5.0000e-01\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.6393 - cosine_proximity: -5.0000e-01\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.6390 - cosine_proximity: -5.0000e-01\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.6387 - cosine_proximity: -5.0000e-01\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.6384 - cosine_proximity: -5.0000e-01\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.6381 - cosine_proximity: -5.0000e-01\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.6378 - cosine_proximity: -5.0000e-01\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.6375 - cosine_proximity: -5.0000e-01\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.6371 - cosine_proximity: -5.0000e-01\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.6368 - cosine_proximity: -5.0000e-01\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.6365 - cosine_proximity: -5.0000e-01\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.6362 - cosine_proximity: -5.0000e-01\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.6359 - cosine_proximity: -5.0000e-01\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.6355 - cosine_proximity: -5.0000e-01\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.6352 - cosine_proximity: -5.0000e-01\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.6349 - cosine_proximity: -5.0000e-01\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.6346 - cosine_proximity: -5.0000e-01\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.6343 - cosine_proximity: -5.0000e-01\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.6339 - cosine_proximity: -5.0000e-01\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.6336 - cosine_proximity: -5.0000e-01\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.6333 - cosine_proximity: -5.0000e-01\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.6330 - cosine_proximity: -5.0000e-01\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.6326 - cosine_proximity: -5.0000e-01\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.6323 - cosine_proximity: -5.0000e-01\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.6320 - cosine_proximity: -5.0000e-01\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.6316 - cosine_proximity: -5.0000e-01\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.6313 - cosine_proximity: -5.0000e-01\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.6310 - cosine_proximity: -5.0000e-01\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.6307 - cosine_proximity: -5.0000e-01\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.6303 - cosine_proximity: -5.0000e-01\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.6300 - cosine_proximity: -5.0000e-01\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.6297 - cosine_proximity: -5.0000e-01\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.6293 - cosine_proximity: -5.0000e-01\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.6290 - cosine_proximity: -5.0000e-01\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.6286 - cosine_proximity: -5.0000e-01\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.6283 - cosine_proximity: -5.0000e-01\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.6280 - cosine_proximity: -5.0000e-01\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.6276 - cosine_proximity: -5.0000e-01\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.6273 - cosine_proximity: -5.0000e-01\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.6270 - cosine_proximity: -5.0000e-01\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.6266 - cosine_proximity: -5.0000e-01\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.6263 - cosine_proximity: -5.0000e-01\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.6259 - cosine_proximity: -5.0000e-01\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.6256 - cosine_proximity: -5.0000e-01\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.6252 - cosine_proximity: -5.0000e-01\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.6249 - cosine_proximity: -5.0000e-01\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.6245 - cosine_proximity: -5.0000e-01\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.6242 - cosine_proximity: -5.0000e-01\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.6239 - cosine_proximity: -5.0000e-01\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.6235 - cosine_proximity: -5.0000e-01\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.6232 - cosine_proximity: -5.0000e-01\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.6228 - cosine_proximity: -5.0000e-01\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.6225 - cosine_proximity: -5.0000e-01\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.6221 - cosine_proximity: -5.0000e-01\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.6218 - cosine_proximity: -5.0000e-01\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.6214 - cosine_proximity: -5.0000e-01\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.6210 - cosine_proximity: -5.0000e-01\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.6207 - cosine_proximity: -5.0000e-01\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.6203 - cosine_proximity: -5.0000e-01\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.6200 - cosine_proximity: -5.0000e-01\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.6196 - cosine_proximity: -5.0000e-01\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.6193 - cosine_proximity: -5.0000e-01\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.6189 - cosine_proximity: -5.0000e-01\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.6186 - cosine_proximity: -5.0000e-01\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.6182 - cosine_proximity: -5.0000e-01\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.6178 - cosine_proximity: -5.0000e-01\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.6175 - cosine_proximity: -5.0000e-01\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.6171 - cosine_proximity: -5.0000e-01\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.6168 - cosine_proximity: -5.0000e-01\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.6164 - cosine_proximity: -5.0000e-01\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.6160 - cosine_proximity: -5.0000e-01\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.6157 - cosine_proximity: -5.0000e-01\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.6153 - cosine_proximity: -5.0000e-01\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.6149 - cosine_proximity: -5.0000e-01\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.6146 - cosine_proximity: -5.0000e-01\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.6142 - cosine_proximity: -5.0000e-01\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6138 - cosine_proximity: -5.0000e-01\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6135 - cosine_proximity: -5.0000e-01\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6131 - cosine_proximity: -5.0000e-01\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6127 - cosine_proximity: -5.0000e-01\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6124 - cosine_proximity: -5.0000e-01\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6120 - cosine_proximity: -5.0000e-01\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6116 - cosine_proximity: -5.0000e-01\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6112 - cosine_proximity: -5.0000e-01\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6109 - cosine_proximity: -5.0000e-01\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6105 - cosine_proximity: -5.0000e-01\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6101 - cosine_proximity: -5.0000e-01\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6097 - cosine_proximity: -5.0000e-01\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6094 - cosine_proximity: -5.0000e-01\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6090 - cosine_proximity: -5.0000e-01\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6086 - cosine_proximity: -5.0000e-01\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6082 - cosine_proximity: -5.0000e-01\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6079 - cosine_proximity: -5.0000e-01\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6075 - cosine_proximity: -5.0000e-01\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6071 - cosine_proximity: -5.0000e-01\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6067 - cosine_proximity: -5.0000e-01\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6063 - cosine_proximity: -5.0000e-01\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6060 - cosine_proximity: -5.0000e-01\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6056 - cosine_proximity: -5.0000e-01\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6052 - cosine_proximity: -5.0000e-01\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6048 - cosine_proximity: -5.0000e-01\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6044 - cosine_proximity: -5.0000e-01\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6040 - cosine_proximity: -5.0000e-01\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6037 - cosine_proximity: -5.0000e-01\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6033 - cosine_proximity: -5.0000e-01\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6029 - cosine_proximity: -5.0000e-01\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6025 - cosine_proximity: -5.0000e-01\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.6021 - cosine_proximity: -5.0000e-01\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.6017 - cosine_proximity: -5.0000e-01\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.6013 - cosine_proximity: -5.0000e-01\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.6010 - cosine_proximity: -5.0000e-01\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.6006 - cosine_proximity: -5.0000e-01\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.6002 - cosine_proximity: -5.0000e-01\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.5998 - cosine_proximity: -5.0000e-01\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.5994 - cosine_proximity: -5.0000e-01\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.5990 - cosine_proximity: -5.0000e-01\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.5986 - cosine_proximity: -5.0000e-01\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.5982 - cosine_proximity: -5.0000e-01\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.5978 - cosine_proximity: -5.0000e-01\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.5974 - cosine_proximity: -5.0000e-01\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.5970 - cosine_proximity: -5.0000e-01\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.5966 - cosine_proximity: -5.0000e-01\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.5962 - cosine_proximity: -5.0000e-01\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.5958 - cosine_proximity: -5.0000e-01\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.5954 - cosine_proximity: -5.0000e-01\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.5950 - cosine_proximity: -5.0000e-01\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.5946 - cosine_proximity: -5.0000e-01\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.5943 - cosine_proximity: -5.0000e-01\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.5939 - cosine_proximity: -5.0000e-01\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.5935 - cosine_proximity: -5.0000e-01\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.5931 - cosine_proximity: -5.0000e-01\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.5927 - cosine_proximity: -5.0000e-01\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.5922 - cosine_proximity: -5.0000e-01\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.5918 - cosine_proximity: -5.0000e-01\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.5914 - cosine_proximity: -5.0000e-01\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.5910 - cosine_proximity: -5.0000e-01\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.5906 - cosine_proximity: -5.0000e-01\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.5902 - cosine_proximity: -5.0000e-01\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.5898 - cosine_proximity: -5.0000e-01\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.5894 - cosine_proximity: -5.0000e-01\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.5890 - cosine_proximity: -5.0000e-01\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.5886 - cosine_proximity: -5.0000e-01\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.5882 - cosine_proximity: -5.0000e-01\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.5878 - cosine_proximity: -5.0000e-01\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.5874 - cosine_proximity: -5.0000e-01\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.5870 - cosine_proximity: -5.0000e-01\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.5866 - cosine_proximity: -5.0000e-01\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.5862 - cosine_proximity: -5.0000e-01\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.5858 - cosine_proximity: -5.0000e-01\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.5854 - cosine_proximity: -5.0000e-01\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.5849 - cosine_proximity: -5.0000e-01\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.5845 - cosine_proximity: -5.0000e-01\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.5841 - cosine_proximity: -5.0000e-01\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.5837 - cosine_proximity: -5.0000e-01\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.5833 - cosine_proximity: -5.0000e-01\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.5829 - cosine_proximity: -5.0000e-01\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.5825 - cosine_proximity: -5.0000e-01\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.5821 - cosine_proximity: -5.0000e-01\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.5816 - cosine_proximity: -5.0000e-01\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.5812 - cosine_proximity: -5.0000e-01\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.5808 - cosine_proximity: -5.0000e-01\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.5804 - cosine_proximity: -5.0000e-01\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.5800 - cosine_proximity: -5.0000e-01\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.5796 - cosine_proximity: -5.0000e-01\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.5792 - cosine_proximity: -5.0000e-01\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.5787 - cosine_proximity: -5.0000e-01\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.5783 - cosine_proximity: -5.0000e-01\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.5779 - cosine_proximity: -5.0000e-01\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.5775 - cosine_proximity: -5.0000e-01\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.5771 - cosine_proximity: -5.0000e-01\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.5766 - cosine_proximity: -5.0000e-01\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.5762 - cosine_proximity: -5.0000e-01\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.5758 - cosine_proximity: -5.0000e-01\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.5754 - cosine_proximity: -5.0000e-01\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.5750 - cosine_proximity: -5.0000e-01\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.5745 - cosine_proximity: -5.0000e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vp_MB0QVEzU",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTYTpK4PFF1A",
        "colab_type": "text"
      },
      "source": [
        "*ACCURACY SCORES*\n",
        "\n",
        "**Accuracy-**\n",
        "\n",
        "Test loss: 0.10376196658944027\n",
        "\n",
        "\n",
        "Test accuracy: 0.9757\n",
        "\n",
        "\n",
        "**binary_accuracy-**\n",
        "\n",
        "Test loss: 0.15646206490577766\n",
        "\n",
        "\n",
        "Test accuracy: 0.9955399974822998\n",
        "\n",
        "\n",
        "**categorical_accuracy-**\n",
        "\n",
        "Test loss: 0.14195446051103405\n",
        "\n",
        "\n",
        "Test accuracy: 0.9816\n",
        "\n",
        "\n",
        "**top_k_categorical_accuracy-**\n",
        "\n",
        "Test loss: 0.15224556388646485\n",
        "\n",
        "\n",
        "Test accuracy: 0.9999\n",
        "\n",
        "\n",
        "**sparse_categorical_accuracy-**\n",
        "\n",
        "loss: 0.4375 \n",
        "\n",
        "\n",
        "sparse_categorical_accuracy: 0.5000\n",
        "\n",
        "\n",
        "**sparse_top_k_categorical_accuracy-**\n",
        "\n",
        "loss: 0.7547 \n",
        "\n",
        "\n",
        "sparse_top_k_categorical_accuracy: 0.5000\n",
        "\n",
        "\n",
        "**cosine_proximity-**\n",
        "\n",
        "loss: 0.7574 \n",
        "\n",
        "\n",
        "cosine_proximity: -5.0000e-01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXtv1hZ7KTzZ",
        "colab_type": "text"
      },
      "source": [
        "The best metric among all is **top_k_categorical_accuracy** which gives almost an accuracy of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LatctACmMT9Y",
        "colab_type": "code",
        "outputId": "b34e6f3f-2023-4253-a858-025953912620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test =  to_categorical(Y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 67us/step - loss: 2.2473 - top_k_categorical_accuracy: 0.7505 - val_loss: 1.7536 - val_top_k_categorical_accuracy: 0.8568\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 3s 54us/step - loss: 1.8082 - top_k_categorical_accuracy: 0.8509 - val_loss: 1.6659 - val_top_k_categorical_accuracy: 0.8857\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 3s 54us/step - loss: 1.7041 - top_k_categorical_accuracy: 0.8728 - val_loss: 1.8074 - val_top_k_categorical_accuracy: 0.8317\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 3s 56us/step - loss: 1.6237 - top_k_categorical_accuracy: 0.8880 - val_loss: 1.6432 - val_top_k_categorical_accuracy: 0.8910\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 1.5699 - top_k_categorical_accuracy: 0.8992 - val_loss: 1.6008 - val_top_k_categorical_accuracy: 0.8908\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 3s 57us/step - loss: 1.5277 - top_k_categorical_accuracy: 0.9062 - val_loss: 1.5868 - val_top_k_categorical_accuracy: 0.8961\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 3s 55us/step - loss: 1.4878 - top_k_categorical_accuracy: 0.9134 - val_loss: 1.5047 - val_top_k_categorical_accuracy: 0.9125\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 3s 57us/step - loss: 1.4543 - top_k_categorical_accuracy: 0.9182 - val_loss: 1.7065 - val_top_k_categorical_accuracy: 0.8813\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 3s 54us/step - loss: 1.4296 - top_k_categorical_accuracy: 0.9229 - val_loss: 1.4939 - val_top_k_categorical_accuracy: 0.9162\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 3s 53us/step - loss: 1.4095 - top_k_categorical_accuracy: 0.9246 - val_loss: 1.5381 - val_top_k_categorical_accuracy: 0.9088\n",
            "Test loss: 1.5381210020065308\n",
            "Test accuracy: 0.9088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eZxoUOWNTpK",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 10**\n",
        "\n",
        "Test loss: 1.5381210020065308\n",
        "\n",
        "\n",
        "Test accuracy: 0.9088"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkNHWHHvNIdL",
        "colab_type": "code",
        "outputId": "bfa12244-0dcd-434c-95e2-6c3f9a7ae159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 100)\n",
        "Y_test =  to_categorical(Y_test, 100)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 64us/step - loss: 4.2952 - top_k_categorical_accuracy: 0.2036 - val_loss: 3.9600 - val_top_k_categorical_accuracy: 0.2928\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 3.7820 - top_k_categorical_accuracy: 0.3419 - val_loss: 3.7000 - val_top_k_categorical_accuracy: 0.3734\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 3.6018 - top_k_categorical_accuracy: 0.3965 - val_loss: 3.6282 - val_top_k_categorical_accuracy: 0.3977\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 3.4651 - top_k_categorical_accuracy: 0.4316 - val_loss: 3.6416 - val_top_k_categorical_accuracy: 0.3966\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 3s 50us/step - loss: 3.3696 - top_k_categorical_accuracy: 0.4536 - val_loss: 3.4982 - val_top_k_categorical_accuracy: 0.4366\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 3.2718 - top_k_categorical_accuracy: 0.4846 - val_loss: 3.7832 - val_top_k_categorical_accuracy: 0.3880\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 3s 50us/step - loss: 3.1992 - top_k_categorical_accuracy: 0.5030 - val_loss: 3.4512 - val_top_k_categorical_accuracy: 0.4609\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 3.1287 - top_k_categorical_accuracy: 0.5185 - val_loss: 3.4786 - val_top_k_categorical_accuracy: 0.4476\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 3.0687 - top_k_categorical_accuracy: 0.5359 - val_loss: 3.5558 - val_top_k_categorical_accuracy: 0.4475\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 3.0115 - top_k_categorical_accuracy: 0.5497 - val_loss: 3.3935 - val_top_k_categorical_accuracy: 0.4830\n",
            "Test loss: 3.393477967834473\n",
            "Test accuracy: 0.483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-5z-Rk_NjXe",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 100**\n",
        "\n",
        "Test loss: 3.393477967834473\n",
        "\n",
        "\n",
        "Test accuracy: 0.483"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbtFF2pVMg1F",
        "colab_type": "code",
        "outputId": "106e8d80-6979-4eb4-bd37-926f3809cef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "Y_train = to_categorical(Y_train, NUM_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.5428 - top_k_categorical_accuracy: 0.9932 - val_loss: 0.6340 - val_top_k_categorical_accuracy: 0.9960\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3741 - top_k_categorical_accuracy: 0.9978 - val_loss: 0.3925 - val_top_k_categorical_accuracy: 0.9978\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.3345 - top_k_categorical_accuracy: 0.9984 - val_loss: 0.3887 - val_top_k_categorical_accuracy: 0.9981\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.3086 - top_k_categorical_accuracy: 0.9986 - val_loss: 0.3435 - val_top_k_categorical_accuracy: 0.9975\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.2895 - top_k_categorical_accuracy: 0.9990 - val_loss: 0.3534 - val_top_k_categorical_accuracy: 0.9980\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2764 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.3573 - val_top_k_categorical_accuracy: 0.9979\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2652 - top_k_categorical_accuracy: 0.9994 - val_loss: 0.3492 - val_top_k_categorical_accuracy: 0.9981\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.2550 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.3955 - val_top_k_categorical_accuracy: 0.9980\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2463 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.4109 - val_top_k_categorical_accuracy: 0.9970\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.2379 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.3457 - val_top_k_categorical_accuracy: 0.9981\n",
            "Test loss: 0.34572943717837334\n",
            "Test accuracy: 0.9981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT_Hk41eNa3K",
        "colab_type": "text"
      },
      "source": [
        "**FASHION_MNIST**\n",
        "\n",
        "Test loss: 0.34572943717837334\n",
        "\n",
        "\n",
        "Test accuracy: 0.9981"
      ]
    }
  ]
}